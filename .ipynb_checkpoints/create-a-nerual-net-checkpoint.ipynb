{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[372]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation, Input, GRU, SimpleRNN, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'C:\\\\Users\\\\Steven\\\\Desktop\\\\New folder\\\\train.csv'\n",
    "test_path = 'C:\\\\Users\\\\Steven\\\\Desktop\\\\New folder\\\\validation.csv'\n",
    "train = pd.read_csv(train_path)\n",
    "#train.drop([0], axis=1)\n",
    "test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['num_risk_deaths'] =  train['risk_deaths'].apply(lambda x: 0 if x == 'low' else 1)\n",
    "train = train.drop(['deaths','confirmed_cases','risk_cases', 'state', 'county_name',\n",
    "           'confirmed_cases_per1000','deaths_per1000', 'risk_deaths', 'county_fips_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['num_risk_deaths'] =  test['risk_deaths'].apply(lambda x: 0 if x == 'low' else 1)\n",
    "test = test.drop(['deaths','confirmed_cases','risk_cases', 'state', 'county_name',\n",
    "           'confirmed_cases_per1000','deaths_per1000', 'risk_deaths', 'county_fips_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_train = train.to_numpy()\n",
    "np_test = test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np_train[:,:-1]\n",
    "y_train = np_train[:, -1]\n",
    "X_test = np_test[:,:-1]\n",
    "y_test = np_test[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[4]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[357]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_all = Input(shape=(X_train.shape[1],))\n",
    "x = Dense(units=32, activation='relu',kernel_initializer='random_normal')(input_all)\n",
    "x = Dense(units=64, activation='relu',kernel_initializer='random_normal')(x)\n",
    "x = Dense(units=128, activation='relu',kernel_initializer='random_normal')(x)\n",
    "x = Dense(units=256, activation='relu',kernel_initializer='random_normal')(x)\n",
    "x = Dense(units=128, activation='relu',kernel_initializer='random_normal')(x)\n",
    "x = Dense(units=64, activation='relu',kernel_initializer='random_normal')(x)\n",
    "x = Dense(units=32, activation='relu',kernel_initializer='random_normal')(x)\n",
    "prediction = Dense(units=1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_all, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                672       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 87,393\n",
      "Trainable params: 87,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='bce',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.893559e-06] [0.99989724] 0.31632623\n",
      "[0.00154553] [0.96249104] 0.33181477\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "\n",
    "input_all = Input(shape=(X_train.shape[1],))\n",
    "x = Dense(units=32, activation='relu',\n",
    "          kernel_initializer='glorot_uniform')(input_all)\n",
    "x = Dense(units=64, activation='relu',kernel_initializer='glorot_uniform')(x)\n",
    "nx = Dense(units=128, activation='relu',kernel_initializer='glorot_uniform')(x)\n",
    "x = Dense(units=256, activation='relu',kernel_initializer='glorot_uniform')(x)\n",
    "prediction = Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=input_all, outputs=prediction)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001,\n",
    "                             beta_1=0.8,\\n                            beta_2=0.99,\n",
    "                             epsilon=1e-06,),\\n              loss='bce',\\n              metrics=['accuracy'])\\n\\n\\nclass_weight = [5,  50]\\n\\nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test),\\n                    epochs=120,  batch_size=50, \\n                    class_weight=class_weight, \\n                    verbose=False)\\nyhat = model.predict(X_train)\\nprint(min(yhat), max(yhat), np.mean(yhat))\\nyhat = model.predict(X_test)\\nprint(min(yhat), max(yhat), np.mean(yhat))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.figure(figsize=(12.8,4.8))\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_acc(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.figure(figsize=(12.8,4.8))\n",
    "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and Validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plot_history(history)\n",
    "yhat = model.predict(X_train).round()\n",
    "print('Train:', accuracy_score(y_train, yhat)*100)\n",
    "yhat = model.predict(X_test).round()\n",
    "print('Validation:', accuracy_score(y_test, yhat)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "yhat = (model.predict(X_test)).round()\n",
    "print(recall_score(y_test, yhat, pos_label=0))\n",
    "print(recall_score(y_test, yhat, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = (model.predict(X_test) + 0.30).round()\n",
    "print(recall_score(y_test, yhat, pos_label=0))\n",
    "print(recall_score(y_test, yhat, pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[414]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('time', '', \"model = None\\nseed(1)\\ntf.random.set_seed(2)\\nfrom tensorflow.python.keras import backend as K\\nsession_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\\nsess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\\nK.set_session(sess)\\n\\ninput_all = Input(shape=(X_train.shape[1],))\\nx = Dense(units=32, activation='relu',\\n          kernel_initializer='glorot_uniform')(input_all)\\nx = Dense(units=64, activation='relu',kernel_initializer='glorot_uniform')(x)\\nx = Dense(units=128, activation='relu',kernel_initializer='glorot_uniform')(x)\\nx = Dense(units=256, activation='relu',kernel_initializer='glorot_uniform')(x)\\nprediction = Dense(units=1, activation='sigmoid')(x)\\n\\nmodel = Model(inputs=input_all, outputs=prediction)\\n\\nmodel.compile(optimizer=Adam(learning_rate=0.0001,\\n                            beta_1=0.8,\\n                            beta_2=0.99,\\n                            epsilon=1e-07,),\\n              loss='bce',\\n              metrics=['accuracy'])\\n\\n\\nclass_weight = [15,  50]\\n\\nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test),\\n                    epochs=120,  batch_size=50, \\n                    class_weight=class_weight, \\n                    verbose=False)\\nyhat = model.predict(X_train)\\nprint(min(yhat), max(yhat), np.mean(yhat))\\nyhat = model.predict(X_test)\\nprint(min(yhat), max(yhat), np.mean(yhat))\\n\\nloss = history.history['loss']\\nval_loss = history.history['val_loss']\\n\\nepochs = range(1, len(loss) + 1)\\n\\nplot_history(history)\\n\\nyhat = model.predict(X_train).round()\\n\\nprint('Train:', accuracy_score(y_train, yhat)*100)\\n\\nyhat = model.predict(X_test).round()\\nprint('Validation:', accuracy_score(y_test, yhat)*100)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[420]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "yhat = (model.predict(X_test)).round()\n",
    "print(recall_score(y_test, yhat, pos_label=0))\n",
    "print(recall_score(y_test, yhat, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = (model.predict(X_test) + 0.075).round()\n",
    "print(recall_score(y_test, yhat, pos_label=0))\n",
    "print(recall_score(y_test, yhat, pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[416]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = (model.predict(X_test))\n",
    "np.mean(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
